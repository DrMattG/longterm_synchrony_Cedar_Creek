---
title: "CIs for linear combinations of parameters"
author: "D. G. Gannon"
date: "2023-02-21"
output: html_document
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE)
library(here)
library(tidyverse)
```

## Three-way interaction model with categories for N

**Note:** I am using the `vr_st_df` object created on line 318 of the `/data_analyses/Clean_figs_1_to_3_stats2022.R` script. I saved this to `/data/clean_model_dat.rds/`.

```{r}

# load data
  vr_st_df <- readRDS(here("data/clean_model_dat.rds"))

# make a factor out of N
  vr_st_df$f_Nitrogen <- as.factor(vr_st_df$Nitrogen)

# Fitting the model
  mfit_catN <- lm(stability ~ VR * disk * f_Nitrogen, data = vr_st_df)
  
 # plot(mfit_catN)
  
```


### Slope estimates for VR in each category

The way we fit the model, we need linear combinations of parameters in the model to recover estimates of the slopes in different disturbance$\times$Nitrogen categories. For example, assume we only have two categories for N (no N and some N added), just to make things easier to write down. Then, the model would be:

$$
y_i = \beta_0 + \beta_1\text{V}_i + \beta_2\text{D}_i + \beta_3\text{N}_i + \beta_4(\text{V}_i\text{D}_i) + \beta_5(\text{V}_i\text{N}_i) + \beta_6(\text{V}_i\text{D}_i\text{N}_i)
$$
where $\text{N}_i$ is 0 when in the reference category for N and 1 when in the other category, and same with $\text{D}_i$. So, let's assume we are in the 0 N and undisturbed plots, then the equation for the line becomes

$$
\begin{aligned}
y_i &= \beta_0 + \beta_1\text{V}_i + \beta_2(0) + \beta_3(0) + \beta_4(\text{V}_i(0)) + \beta_5(\text{V}_i(0)) + \beta_6(\text{V}_i(0)(0))\\
&= \beta_0 + \beta_1\text{V}_i,
\end{aligned}
$$
so the slope in that category is simply $\beta_1$ and we can use the output from `lm()` to compute the confidence interval. However, if we are in the undisturbed plot with the added N treatment (again, just assuming a no N and added N treatment for simplicity here), then we have

$$
\begin{aligned}
y_i &= \beta_0 + \beta_1\text{V}_i + \beta_2(0) + \beta_3(1) + \beta_4(\text{V}_i(0)) + \beta_5(\text{V}_i(1)) + \beta_6(\text{V}_i(0)(1))\\
&=\beta_0 + \beta_1\text{V}_i + \beta_5\text{V}_i\\
&= \beta_0 + (\beta_1 + \beta_5)\text{V}_i,
\end{aligned}
$$
so the slope for the variance ratio -- stability relationship in this category is $(\beta_1 + \beta_5)$. For any other category except the reference category, the slope will be a linear combination of parameters.

It is therefore easy to get the slope estimate in different categories (just sum up the appropriate parameter estimates), but what about the confidence interval? For that we need the standard error of the estimate,
$$
\hat\sigma = [\text{Var}(\hat\beta_1 + \hat\beta_5)]^{1/2} = [\text{Var}(\hat\beta_1) + \text{Var}(\hat\beta_5) + 2\text{Cov}(\hat\beta_1, \hat\beta_5)]^{1/2}
$$
such that we can construct a confidence interval
$$
(\hat\beta_1 + \hat\beta_5) \pm t^*\hat\sigma
$$
where $t^*$ is the quantile of a $t$-distribution with $n-p$ degrees of freedom, where $p$ is the number of parameters in the model (*The degrees of freedom always come from the degrees of freedom for the residual variance estimate.*).

### Generalizing for any linear combination.

The linear combination $\hat\beta_1 + \hat\beta_5$ can be written as ${\bf v}^\top\boldsymbol\beta$, where the vector ${\bf v}^\top = (0,\ 1,\ 0,\ 0,\ 1, 0)$ and $\boldsymbol\beta$ is the vector of regression coefficients. So we can design $\bf v$ in order to construct any linear combination of parameters we want. We can use this general form, ${\bf v}^\top \boldsymbol\beta$, and properties of variances to also get the standard error of the linear combination:

$$
\text{Var}({\bf v}^\top \hat{\boldsymbol\beta}) = {\bf v}^\top\text{Var}(\hat{\boldsymbol\beta}){\bf v}
$$
since ${\bf v}$ is fixed and known, and the SE is the square root of this variance estimate. So, we just need the covariance matrix of $\hat{\boldsymbol\beta}$ and our designed $\bf v$ to compute the confidence interval.

### Doing this for lots of linear combinations at once

Since we need slope estimates for a bunch of different categories, it is useful to extend this to a matrix $\bf V$ with one row per linear combination of parameters. Taking the example above with a hypothetical 2 N treatment (none or some), we could set

$$
{\bf V} = \begin{bmatrix}
0 & 1 & 0 & 0 & 0 & 0 & 0\\
0 & 1 & 0 & 0 & 1 & 0 & 0\\
0 & 1 & 0 & 0 & 0 & 1 & 0\\
0 & 1 & 0 & 0 & 1 & 1 & 1\\
\end{bmatrix}
$$
such that each row corresponds to the linear combination of parameters we need to compute the slope for each category. Namely:

* Row 1: No Dist. No N
* Row 2: Yes Dist. No N
* Row 3: No Dist. Yes N
* Row 4: Yes Dist. Yes N

Then, the variance-covariance matrix for the *vector* of slope estimates is

$$
\text{Var}({\bf V}\hat{\boldsymbol\beta}) = {\bf V}\text{Var}(\hat{\boldsymbol\beta}){\bf V}^\top
$$
and we can pull out the diagonal of this matrix and take the square root to get each of the standard errors for each slope.

## Example for one slope from the CC experiment

As an example with code, let's compute the estimate and CI for the slope of the relationship between stability and VR in the disturbed plot with 2.0 nitrogen treatment:

```{r}

# extract regression coefficients
  (beta_hat <- mfit_catN$coefficients)

# extract covariance matrix
  S_beta <- vcov(mfit_catN)

# construct v, given the names of the coefficients
  v <- rep(0, length(beta_hat))
  
# we need the reference level VR slope and any interaction term that includes VR but doesn't get set to zero
# for this, the disk1 and f_Nitrogen2 dummy variables will be 1 while all others will be 0.
  params <- c(
    "VR",
    "VR:disk1",
    "VR:f_Nitrogen2",
    "VR:disk1:f_Nitrogen2"
  )
  
# set the elements in v that correspond to these parameters to 1 
  v[which(names(beta_hat) %in% params)] <- 1
  
# compute estimate and standard error
  estim_diskN2 <- as.double(v %*% beta_hat)
  se_diskN2 <- as.double(sqrt(v %*% S_beta %*% v))
  
# compute the confidence interval
  t_star <- qt(0.975, df = nrow(vr_st_df) - length(beta))
  (ci_diskN2 <- estim_diskN2 + c(-1, 1) * t_star * se_diskN2)


```

### Sanity check

This estimate should be identical to what we get when subsetting and fitting the simple linear model, but the confidence interval will better reflect the full covariance structure among our variables of interest.

```{r}

# subset to check
  subdiskN2 <- vr_st_df %>% filter(
    disk == 1 & f_Nitrogen == "2"
  )

# calculate stats from subset
  mfit_sub <- lm(stability ~ VR, data = subdiskN2)
  coef_sub <- mfit_sub$coefficients[2]
  se_sub <- sqrt(vcov(mfit_sub)[2,2])
  t_star_sub <- qt(0.975, df = nrow(subdiskN2) - 2)
  ci_sub <- coef_sub + c(-1, 1) * t_star_sub * se_sub
  
# compare
  compare_tbl <- rbind(
      c(estim_diskN2, ci_diskN2),
      c(coef_sub, ci_sub)
    )
  rownames(compare_tbl) <- c("single model", "separate analyses")
  
  
  kableExtra::kable(
    compare_tbl,
    format = "pipe",
    col.names = c("Estim", "Lower", "Upper"),
    digits = 2
  )

```


In this case, the CIs from the full model might be narrower because of increased degrees of freedom available to estimate the residual variance, but this would not be the case if there were strong collinearity among our explanatory variables, which is why it is generally safer to fit and report on the full model.


$~$

$~$








